---
layout: post
title: "PITA - Probabilistic Inference-time Algorithm"
date: 2025-12-1
image: 
---

I've been interested in seeing the ways probabilistic algorithms like Markov Chain Monte Carlo (MCMC) and Sequential Monte Carlo (SMC)/particle filtering can be applied to increasing the reasoning capapbilities of lanaguge models at test-time. Recently, papers from Karan and Du (https://arxiv.org/pdf/2510.14901) and Puri, et al. (https://arxiv.org/pdf/2502.01618) have inspired me to see if I can combine these algorithms in a way to extend the reasoning performance of smaller lanaguge models. Inference-time scaling is cool because it opens the door to having smarter models locally where memory constraints prevent have a model that is typically tens of billions of parameters. 

The idea behind the first paper, "Reasoning with Sampling" is pretty straightforward (in retrospect). Instead of doing low-temperature sampling from a langauge model or using RL to tilt the model's posterior based on some reward function, Karan and Du show that you can extract reasoning-like traces and ultimately benchmark performance on-par with GRPO fine-tuned models simply by sampling from a sharpened version of the base model's posterior - $p_{LLM}(x)^\alpha$. To be continued...
